{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from abc import ABC, abstractmethod\n",
    " \n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Helper Functions\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    \"\"\"Return a normalization layer\n",
    "    Parameters:\n",
    "        norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
    "    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
    "    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n",
    "    \"\"\"\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "    elif norm_type == 'none':\n",
    "        def norm_layer(x): return Identity()\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, opt):\n",
    "    \"\"\"Return a learning rate scheduler\n",
    "    Parameters:\n",
    "        optimizer          -- the optimizer of the network\n",
    "        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions．　\n",
    "                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n",
    "    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
    "    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
    "    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n",
    "    See https://pytorch.org/docs/stable/optim.html for more details.\n",
    "    \"\"\"\n",
    "    if opt.lr_policy == 'linear':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + opt.epoch_count - opt.n_epochs) / float(opt.n_epochs_decay + 1)\n",
    "            return lr_l\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif opt.lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
    "    elif opt.lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    elif opt.lr_policy == 'cosine':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=opt.n_epochs, eta_min=0)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"Initialize network weights.\n",
    "    Parameters:\n",
    "        net (network)   -- network to be initialized\n",
    "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
    "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
    "    work better for some applications. Feel free to try yourself.\n",
    "    \"\"\"\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>\n",
    "\n",
    "\n",
    "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
    "    Parameters:\n",
    "        net (network)      -- the network to be initialized\n",
    "        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Return an initialized network.\n",
    "    \"\"\"\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert(torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
    "    init_weights(net, init_type, init_gain=init_gain)\n",
    "    return net\n",
    "\n",
    "\n",
    "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Create a generator\n",
    "    Parameters:\n",
    "        input_nc (int) -- the number of channels in input images\n",
    "        output_nc (int) -- the number of channels in output images\n",
    "        ngf (int) -- the number of filters in the last conv layer\n",
    "        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n",
    "        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n",
    "        use_dropout (bool) -- if use dropout layers.\n",
    "        init_type (str)    -- the name of our initialization method.\n",
    "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Returns a generator\n",
    "    Our current implementation provides two types of generators:\n",
    "        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
    "        The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
    "        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n",
    "        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n",
    "        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n",
    "    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n",
    "    \"\"\"\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netG == 'resnet_9blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9)\n",
    "    elif netG == 'resnet_6blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6)\n",
    "    else:\n",
    "        raise NotImplementedError('Generator model name [%s] is not recognized' % netG)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "\n",
    "def define_D(input_nc, ndf, netD, n_layers_D=3, norm='batch', init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Create a discriminator\n",
    "    Parameters:\n",
    "        input_nc (int)     -- the number of channels in input images\n",
    "        ndf (int)          -- the number of filters in the first conv layer\n",
    "        netD (str)         -- the architecture's name: basic | n_layers | pixel\n",
    "        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n",
    "        norm (str)         -- the type of normalization layers used in the network.\n",
    "        init_type (str)    -- the name of the initialization method.\n",
    "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Returns a discriminator\n",
    "    Our current implementation provides three types of discriminators:\n",
    "        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n",
    "        It can classify whether 70×70 overlapping patches are real or fake.\n",
    "        Such a patch-level discriminator architecture has fewer parameters\n",
    "        than a full-image discriminator and can work on arbitrarily-sized images\n",
    "        in a fully convolutional fashion.\n",
    "        [n_layers]: With this mode, you can specify the number of conv layers in the discriminator\n",
    "        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n",
    "        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n",
    "        It encourages greater color diversity but has no effect on spatial statistics.\n",
    "    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n",
    "    \"\"\"\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netD == 'basic':  # default PatchGAN classifier\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer)\n",
    "    elif netD == 'n_layers':  # more options\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer)\n",
    "    elif netD == 'pixel':     # classify if each pixel is real or fake\n",
    "        net = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer)\n",
    "    else:\n",
    "        raise NotImplementedError('Discriminator model name [%s] is not recognized' % netD)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Classes\n",
    "##############################################################################\n",
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Define different GAN objectives.\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
    "        \"\"\" Initialize the GANLoss class.\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_fake_label (bool) - - label of a fake image\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        self.gan_mode = gan_mode\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode in ['wgangp']:\n",
    "            self.loss = None\n",
    "        else:\n",
    "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        \"\"\"Create label tensors with the same size as the input.\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "        Returns:\n",
    "            A label tensor filled with ground truth label, and with the size of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "        Returns:\n",
    "            the calculated loss.\n",
    "        \"\"\"\n",
    "        if self.gan_mode in ['lsgan', 'vanilla']:\n",
    "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "            loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgangp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        \"\"\"Construct a Resnet-based generator\n",
    "        Parameters:\n",
    "            input_nc (int)      -- the number of channels in input images\n",
    "            output_nc (int)     -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Initialize the Resnet block\n",
    "        A resnet block is a conv block with skip connections\n",
    "        We construct a conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> function.\n",
    "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Construct a convolutional block.\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
    "        \"\"\"\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out\n",
    "\n",
    "\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class PixelDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a 1x1 PatchGAN discriminator (pixelGAN)\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a 1x1 PatchGAN discriminator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(PixelDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        self.net = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=1, stride=1, padding=0),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=1, stride=1, padding=0, bias=use_bias),\n",
    "            norm_layer(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf * 2, 1, kernel_size=1, stride=1, padding=0, bias=use_bias)]\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(ABC):\n",
    "    \"\"\"This class is an abstract base class (ABC) for models.\n",
    "    To create a subclass, you need to implement the following five functions:\n",
    "        -- <__init__>:                      initialize the class; first call BaseModel.__init__(self, opt).\n",
    "        -- <set_input>:                     unpack data from dataset and apply preprocessing.\n",
    "        -- <forward>:                       produce intermediate results.\n",
    "        -- <optimize_parameters>:           calculate losses, gradients, and update network weights.\n",
    "        -- <modify_commandline_options>:    (optionally) add model-specific options and set default options.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        \"\"\"Initialize the BaseModel class.\n",
    "        Parameters:\n",
    "            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n",
    "        When creating your custom class, you need to implement your own initialization.\n",
    "        In this function, you should first call <BaseModel.__init__(self, opt)>\n",
    "        Then, you need to define four lists:\n",
    "            -- self.loss_names (str list):          specify the training losses that you want to plot and save.\n",
    "            -- self.model_names (str list):         define networks used in our training.\n",
    "            -- self.visual_names (str list):        specify the images that you want to display and save.\n",
    "            -- self.optimizers (optimizer list):    define and initialize optimizers. You can define one optimizer for each network. If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.\n",
    "        \"\"\"\n",
    "        self.opt = opt\n",
    "        self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')  # get device name: CPU or GPU\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)  # save all the checkpoints to save_dir\n",
    "        if opt.preprocess != 'scale_width':  # with [scale_width], input images might have different sizes, which hurts the performance of cudnn.benchmark.\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.loss_names = []\n",
    "        self.model_names = []\n",
    "        self.visual_names = []\n",
    "        self.optimizers = []\n",
    "        self.image_paths = []\n",
    "        self.metric = 0  # used for learning rate policy 'plateau'\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train):\n",
    "        \"\"\"Add new model-specific options, and rewrite default values for existing options.\n",
    "        Parameters:\n",
    "            parser          -- original option parser\n",
    "            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n",
    "        Returns:\n",
    "            the modified parser.\n",
    "        \"\"\"\n",
    "        return parser\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_input(self, input):\n",
    "        \"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n",
    "        Parameters:\n",
    "            input (dict): includes the data itself and its metadata information.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self):\n",
    "        \"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def optimize_parameters(self):\n",
    "        \"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup(self, opt):\n",
    "        \"\"\"Load and print networks; create schedulers\n",
    "        Parameters:\n",
    "            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n",
    "        \"\"\"\n",
    "        if self.isTrain:\n",
    "            self.schedulers = [networks.get_scheduler(optimizer, opt) for optimizer in self.optimizers]\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            load_suffix = 'iter_%d' % opt.load_iter if opt.load_iter > 0 else opt.epoch\n",
    "            self.load_networks(load_suffix)\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Make models eval mode during test time\"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                net = getattr(self, 'net' + name)\n",
    "                net.eval()\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        \"\"\" Return image paths that are used to load current data\"\"\"\n",
    "        return self.image_paths\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        \"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"\n",
    "        for scheduler in self.schedulers:\n",
    "            if self.opt.lr_policy == 'plateau':\n",
    "                scheduler.step(self.metric)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print('learning rate = %.7f' % lr)\n",
    "\n",
    "    def get_current_losses(self):\n",
    "        \"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"\n",
    "        errors_ret = OrderedDict()\n",
    "        for name in self.loss_names:\n",
    "            if isinstance(name, str):\n",
    "                errors_ret[name] = float(getattr(self, 'loss_' + name))  # float(...) works for both scalar tensor and float number\n",
    "        return errors_ret\n",
    "\n",
    "    def save_networks(self, epoch):\n",
    "        \"\"\"Save all the networks to the disk.\n",
    "        Parameters:\n",
    "            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
    "        \"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                save_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "                save_path = os.path.join(self.save_dir, save_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "\n",
    "                if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "                    torch.save(net.module.cpu().state_dict(), save_path)\n",
    "                    net.cuda(self.gpu_ids[0])\n",
    "                else:\n",
    "                    torch.save(net.cpu().state_dict(), save_path)\n",
    "\n",
    "    def __patch_instance_norm_state_dict(self, state_dict, module, keys, i=0):\n",
    "        \"\"\"Fix InstanceNorm checkpoints incompatibility (prior to 0.4)\"\"\"\n",
    "        key = keys[i]\n",
    "        if i + 1 == len(keys):  # at the end, pointing to a parameter/buffer\n",
    "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
    "                    (key == 'running_mean' or key == 'running_var'):\n",
    "                if getattr(module, key) is None:\n",
    "                    state_dict.pop('.'.join(keys))\n",
    "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
    "               (key == 'num_batches_tracked'):\n",
    "                state_dict.pop('.'.join(keys))\n",
    "        else:\n",
    "            self.__patch_instance_norm_state_dict(state_dict, getattr(module, key), keys, i + 1)\n",
    "\n",
    "    def load_networks(self, epoch):\n",
    "        \"\"\"Load all the networks from the disk.\n",
    "        Parameters:\n",
    "            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
    "        \"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                load_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "                load_path = os.path.join(self.save_dir, load_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "                if isinstance(net, torch.nn.DataParallel):\n",
    "                    net = net.module\n",
    "                print('loading the model from %s' % load_path)\n",
    "                # if you are using PyTorch newer than 0.4 (e.g., built from\n",
    "                # GitHub source), you can remove str() on self.device\n",
    "                state_dict = torch.load(load_path, map_location=str(self.device))\n",
    "                if hasattr(state_dict, '_metadata'):\n",
    "                    del state_dict._metadata\n",
    "\n",
    "                # patch InstanceNorm checkpoints prior to 0.4\n",
    "                for key in list(state_dict.keys()):  # need to copy keys here because we mutate in loop\n",
    "                    self.__patch_instance_norm_state_dict(state_dict, net, key.split('.'))\n",
    "                net.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        \"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n",
    "        Parameters:\n",
    "            nets (network list)   -- a list of networks\n",
    "            requires_grad (bool)  -- whether the networks require gradients or not\n",
    "        \"\"\"\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixModel(BaseModel):\n",
    "    \"\"\" This class implements the pix2pix model, for learning a mapping from input images to output images given paired data.\n",
    "    The model training requires '--dataset_mode aligned' dataset.\n",
    "    By default, it uses a '--netG unet256' U-Net generator,\n",
    "    a '--netD basic' discriminator (PatchGAN),\n",
    "    and a '--gan_mode' vanilla GAN loss (the cross-entropy objective used in the orignal GAN paper).\n",
    "    pix2pix paper: https://arxiv.org/pdf/1611.07004.pdf\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train=True):\n",
    "        \"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n",
    "        Parameters:\n",
    "            parser          -- original option parser\n",
    "            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n",
    "        Returns:\n",
    "            the modified parser.\n",
    "        For pix2pix, we do not use image buffer\n",
    "        The training objective is: GAN Loss + lambda_L1 * ||G(A)-B||_1\n",
    "        By default, we use vanilla GAN loss, UNet with batchnorm, and aligned datasets.\n",
    "        \"\"\"\n",
    "        # changing the default values to match the pix2pix paper (https://phillipi.github.io/pix2pix/)\n",
    "        parser.set_defaults(norm='batch', netG='unet_256', dataset_mode='aligned')\n",
    "        if is_train:\n",
    "            parser.set_defaults(pool_size=0, gan_mode='vanilla')\n",
    "            parser.add_argument('--lambda_L1', type=float, default=100.0, help='weight for L1 loss')\n",
    "\n",
    "        return parser\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        \"\"\"Initialize the pix2pix class.\n",
    "        Parameters:\n",
    "            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n",
    "        \"\"\"\n",
    "        BaseModel.__init__(self, opt)\n",
    "        # specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>\n",
    "        self.loss_names = ['G_GAN', 'G_L1', 'D_real', 'D_fake']\n",
    "        # specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>\n",
    "        self.visual_names = ['real_A', 'fake_B', 'real_B']\n",
    "        # specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>\n",
    "        if self.isTrain:\n",
    "            self.model_names = ['G', 'D']\n",
    "        else:  # during test time, only load G\n",
    "            self.model_names = ['G']\n",
    "        # define networks (both generator and discriminator)\n",
    "        self.netG = networks.define_G(opt.input_nc, opt.output_nc, opt.ngf, opt.netG, opt.norm,\n",
    "                                      not opt.no_dropout, opt.init_type, opt.init_gain, self.gpu_ids)\n",
    "\n",
    "        if self.isTrain:  # define a discriminator; conditional GANs need to take both input and output images; Therefore, #channels for D is input_nc + output_nc\n",
    "            self.netD = networks.define_D(opt.input_nc + opt.output_nc, opt.ndf, opt.netD,\n",
    "                                          opt.n_layers_D, opt.norm, opt.init_type, opt.init_gain, self.gpu_ids)\n",
    "\n",
    "        if self.isTrain:\n",
    "            # define loss functions\n",
    "            self.criterionGAN = networks.GANLoss(opt.gan_mode).to(self.device)\n",
    "            self.criterionL1 = torch.nn.L1Loss()\n",
    "            # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.\n",
    "            self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(self.netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D)\n",
    "\n",
    "    def set_input(self, input):\n",
    "        \"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n",
    "        Parameters:\n",
    "            input (dict): include the data itself and its metadata information.\n",
    "        The option 'direction' can be used to swap images in domain A and domain B.\n",
    "        \"\"\"\n",
    "        AtoB = self.opt.direction == 'AtoB'\n",
    "        self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
    "        self.real_B = input['B' if AtoB else 'A'].to(self.device)\n",
    "        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"\n",
    "        self.fake_B = self.netG(self.real_A)  # G(A)\n",
    "\n",
    "    def backward_D(self):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\"\"\"\n",
    "        # Fake; stop backprop to the generator by detaching fake_B\n",
    "        fake_AB = torch.cat((self.real_A, self.fake_B), 1)  # we use conditional GANs; we need to feed both input and output to the discriminator\n",
    "        pred_fake = self.netD(fake_AB.detach())\n",
    "        self.loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        # Real\n",
    "        real_AB = torch.cat((self.real_A, self.real_B), 1)\n",
    "        pred_real = self.netD(real_AB)\n",
    "        self.loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # combine loss and calculate gradients\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "\n",
    "    def backward_G(self):\n",
    "        \"\"\"Calculate GAN and L1 loss for the generator\"\"\"\n",
    "        # First, G(A) should fake the discriminator\n",
    "        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n",
    "        pred_fake = self.netD(fake_AB)\n",
    "        self.loss_G_GAN = self.criterionGAN(pred_fake, True)\n",
    "        # Second, G(A) = B\n",
    "        self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B) * self.opt.lambda_L1\n",
    "        # combine loss and calculate gradients\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()                   # compute fake images: G(A)\n",
    "        # update D\n",
    "        self.set_requires_grad(self.netD, True)  # enable backprop for D\n",
    "        self.optimizer_D.zero_grad()     # set D's gradients to zero\n",
    "        self.backward_D()                # calculate gradients for D\n",
    "        self.optimizer_D.step()          # update D's weights\n",
    "        # update G\n",
    "        self.set_requires_grad(self.netD, False)  # D requires no gradients when optimizing G\n",
    "        self.optimizer_G.zero_grad()        # set G's gradients to zero\n",
    "        self.backward_G()                   # calculate graidents for G\n",
    "        self.optimizer_G.step()             # udpate G's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
